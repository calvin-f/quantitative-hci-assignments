---
title: ' QHCI 2021 - Project 2'
author: ' Tobias Boner (17-707-878)'
date: "10.05.2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

This project is based on the paper *[How We Type: Movement Strategies and Performance in Everyday Typing](https://dl.acm.org/doi/10.1145/2858036.2858233)*.
We used the data set the authors have provided within the course of their study.
The aim of the data analysis will be to answer the following to research questions (*RQ*):

*	*RQ1: Do overall typing speed differ between touch-typist and non-touchtypist?*

* *RQ2: How much does the result from RQ1 influenced by whether the participants type known-words or random string?*
	
The analysis will base on the **within-subject design** of the study including **one independent variable *(IV)* ** that has **three levels**.
The **IV  *stimulus tpye* ** refers to the type of string users had to type in for the transcription and has three levels:

* *sentences*: easy regular sentences
* *random*: random sequences of letters
* *mix*: a mix of the two other conditions

For the experiments they used a **randomized order** for the three *stimulus types*.



# Data Analysis 

Within this part we will analyze the data set and try to answer the two research questions.

## Setup 

Before we can jump in the analysis we start with setting up the required dependencies for this R notebook.

```{r, results='hide', message=FALSE,  warning=FALSE}
# load the packages
library(tidyverse)
library(lme4)
library(ggplot2)
library(broom.mixed)
library(lmerTest)  
library(plyr)
library(lsm)
library(car)
library(stringr)
```

Some of the required packages have to be installed extra.

```{r, results='hide', message=FALSE, warning=FALSE}
# define addtitional packages
additional_packages <- c("multcomp", "PearsonDS", "ARTool", "qqplotr", "psych", "moments")

# only install additional packages when they are not already included
install.packages(setdiff(additional_packages, rownames(installed.packages())))  
```
To finish the setup we need to load the remaining packages fo finish the setup. 

```{r, results='hide'}
# load the remaining additional packages
import::from(moments, skewness)
import::from(MASS,mvrnorm)
import::from(broom.mixed,tidy)
import::from(multcomp, glht, mcp, adjusted) 
import::from(PearsonDS, rpearson)                                   
import::from(ARTool, art, artlm, art.con)                  
import::from(qqplotr, stat_qq_line, stat_qq_point, stat_qq_band) 
import::from(psych, d.ci) 
import::from(cowplot, plot_grid) 
import::from(modelr, add_residuals, add_predictions)     
import::from(car, leveneTest, sigmaHat)
```

***

## Data Processing ##

Next we can start with the data processing.
First of, we define a helper function `read_log_files` that will help read in all the different log files.

```{r, message=FALSE}
# Regular expression to help parse the log files
regex_parse <- "User(\\d+)_T(\\d+)_(.*).csv"

# helper function to read in log files
read_log_files <- function(fileName){
  csv_data <- read_csv(str_c('./log/',fileName)) %>% 
      mutate(length = str_length(stimulus)) %>% 
      group_by(stimulus_index) %>% 
      summarise(wpm = (as.double(max(length)-1)/5)/ as.double(max(input_time_ms)) * 60000, length = max(length)) %>% 
      mutate(user_id = as.numeric(str_replace(fileName, regex_parse, "\\1")), condition = str_replace(fileName, regex_parse, "\\3"))
    return(csv_data)
}
```

Thereafter, we define all the existing log files (`log_files`) and and the csv containing the participant information (`participant_info`).

```{r, results='hide', message=FALSE, }
# list of all log files
log_files <- list.files('./log')

# file that includes the participant information
participant_info <- read_csv("participant_info.csv")

# backup file that is already processed
combined_log_background <- read_csv(("combined_log_background.csv"))
```

Now we are ready to process the log files and create the data we need.

```{r, results='hide', message=FALSE,}
# data wrangling
data <- as_tibble_col(lapply(log_files, read_log_files), col='nested') %>% 
        unnest(nested) %>% merge(y=participant_info, by='user_id', all.x = TRUE ) %>% 
        mutate(typing_style = if_else(is_touchtypist, 'Non-touchtypist', 'Touchtypist')) %>% 
        select(-is_touchtypist, -length)

# ? TODO add comment
data_with_cond <- data %>% mutate(condition = factor(condition, levels = c("Sentences", "Mix", "Random")), typing_style = factor(typing_style, levels = c("Non-touchtypist", "Touchtypist")))
```

> Note that the *IV stimulus type* is now referred to as *condition* in our data set with the same three levels (*Sentences, Random, Mix*).
> The *typing style* will still be referred to as *typing style*.

***

## Data Exploration and Description

After having processed the data, we now want to inspect and explore it to get a better overview. To do so we can describe its basic properties.

### General Information ###

Thus, it is a good idea to have a quick look at the data by using `head(data)`.
```{r, echo=FALSE}
head(data)
```
Next we check the structure of the data object with `str(data)` and can see the data types of each column.
```{r, echo=FALSE}
str(data)
```
Out data set contains `r ncol(data)` columns (*`r colnames(data)`*) and `r nrow(data)` rows for `r n_distinct(data$user_id)` different users.



### Descriptive Statisctics 

Now that we know how the data looks and what type of data it contains, we can have a look at the data itself.
To get a broad overview of the data we use the  `summary` function.

```{r, echo=FALSE}
summary(data)
```
Out of this summary we get several statistical measures for the first three columns *`r colnames(data[0:3])`* that contain numerical data. For the remaining two rows *`r colnames(data[3:4])`* including strings we get again the length of the columns.

In order to answer the research questions we will now have a look at the *words per minute (wpm)* first with regards to the *typing style* (RQ1) and then in connection with the different *conditions* (RQ2).
To support this process we will also create suitable visualizations for the data sets.


#### **RQ1 - words per minute (wpm) by typing styles**

First we create a violin plot that includes boxplots for *words per minute (wpm)* by the *typing styles* of users.

```{r, echo=FALSE}
# violin plot including boxplots displaying words per minute (wpm) for the two typing styles
data %>% 
  ggplot(aes(x=typing_style, y=wpm, fill=typing_style)) + 
    geom_violin() + 
    geom_boxplot(width=0.1) +
    # add mean to compare to median
    stat_summary(fun=mean, geom="point",  aes(shape="mean"), , size=5, color="red", fill="red") +
    scale_shape_manual("", values=c("mean"="x")) +
    scale_fill_brewer(palette="Blues") + 
    theme_minimal() +
    labs(title="Words Per Minute (WPM) per Typing Style",x="Typing Style", y = "Words Per Minute (WPM)") +
    guides(fill=guide_legend(title="Typing Style"))
```

Out of this first visualization, we can already imply that there is no big difference between the two *typing styles* with regards to *words per minutes (wpm)*. This is also shown in the numbers.

Skewness is a commonly used measure of the symmetry of a statistical distribution. A negative skewness indicates that the distribution is left skewed and the mean of the data (average) is less than the median value

**Non-Parametric Statisctics**

```{r, echo=FALSE}
# median of wpm per typing style
median_wpm_by_typing_style <- by(data = data$wpm, INDICES = data$typing_style, FUN = median) %>%
  rbind() %>%
  as_tibble()

# min of wpm per typing style
min_wpm_by_typing_style <- by(data = data$wpm, INDICES = data$typing_style, FUN = min) %>%
  rbind() %>%
  as_tibble()

# max of wpm per typing style
max_wpm_by_typing_style <- by(data = data$wpm, INDICES = data$typing_style, FUN = max) %>%
  rbind() %>%
  as_tibble()

# IQR of wpm per typing style
iqr_wpm_by_typing_style <- by(data = data$wpm, INDICES = data$typing_style, FUN = IQR) %>%
  rbind() %>%
  as_tibble()
```


* Median:
  + On the one hand `r colnames(median_wpm_by_typing_style[1])` has a `median` of `r median_wpm_by_typing_style[[1]]` *wpms*  and on the other hand `r colnames(median_wpm_by_typing_style[2])` has a `median` of `r median_wpm_by_typing_style[[2]]` *wpms*.

* Min and Max Values:
  + For the `min` values `r colnames(min_wpm_by_typing_style[1])` has a value of `r min_wpm_by_typing_style[[1]]` *wpms* and  `r colnames(min_wpm_by_typing_style[2])` has a value of `r min_wpm_by_typing_style[[2]]` *wpms*.
  + Regarding the `max`values `r colnames(max_wpm_by_typing_style[1])` has a value of `r max_wpm_by_typing_style[[1]]` *wpms* and  `r colnames(max_wpm_by_typing_style[2])` has a value of `r max_wpm_by_typing_style[[2]]` *wpms*.
  
* Interquartile Range (IQR) :
  + The `IQR` of `r colnames(iqr_wpm_by_typing_style[1])` amounts to `r iqr_wpm_by_typing_style[[1]]` and on the `IQR` for  `r colnames(iqr_wpm_by_typing_style[2])` to `r iqr_wpm_by_typing_style[[2]]`.

These non-parametric statistical properties confirm the initial impressions from the visualization above that there are only slight differences between the two *typing styles* with regards to *words per minute (wpm)*. The `median`, `min`, `max`, as well as the `IQR` reveal only small differences.

**Parametric Statistics**

```{r, echo=FALSE}
# mean of wpm per typing style
mean_wpm_by_typing_style <- by(data = data$wpm, INDICES = data$typing_style, FUN = mean) %>%
  rbind() %>%
  as_tibble()

# variation of wpm per typing style
var_wpm_by_typing_style <- by(data = data$wpm, INDICES = data$typing_style, FUN = var) %>%
  rbind() %>%
  as_tibble()

# standard deviation of wpm per typing style
sd_wpm_by_typing_style <- by(data = data$wpm, INDICES = data$typing_style, FUN = sd) %>%
  rbind() %>%
  as_tibble()
```


* Mean:
  + On the one hand `r colnames(mean_wpm_by_typing_style[1])` has a `mean` of `r mean_wpm_by_typing_style[[1]]` *wpms*  and on the other hand `r colnames(mean_wpm_by_typing_style[2])` has a `mean` of `r mean_wpm_by_typing_style[[2]]` *wpms*.

* Spread:
  + For the variance (`var`), `r colnames(min_wpm_by_typing_style[1])` has a value of `r var_wpm_by_typing_style[[1]]` and  `r colnames(var_wpm_by_typing_style[2])` has a value of `r var_wpm_by_typing_style[[2]]`.
  + Regarding the standard deviation, (`sd`) `r colnames(sd_wpm_by_typing_style[1])` accounts to `r sd_wpm_by_typing_style[[1]]` and `r colnames(sd_wpm_by_typing_style[2])` to `r sd_wpm_by_typing_style[[2]]`.
  
These numbers shows that also the parametric statistical properties in the form of `mean`, variance(`var`) and standard deviation(`sd`) are quite similar.


Now that we have concrete numbers for both the `mean` and the `median` for *typing styles* by *wpms* we can make a statement about the distributions of the data and their shapes.
For `r colnames(mean_wpm_by_typing_style[1])` that have a `mean` of `r mean_wpm_by_typing_style[[1]]` *wpms* and a `median` of `r median_wpm_by_typing_style[[1]]` *wpms*, the shape is `r  ifelse(mean_wpm_by_typing_style[[1]] < median_wpm_by_typing_style[[1]],"skewed left", ifelse(mean_wpm_by_typing_style[[1]] > median_wpm_by_typing_style[[1]], "skewed right", "identical"))`.
The same applies For `r colnames(mean_wpm_by_typing_style[2])` that have a `mean` of `r mean_wpm_by_typing_style[[2]]` *wpms* and a `median` of `r median_wpm_by_typing_style[[2]]` *wpms*, where the shape is `r  ifelse(mean_wpm_by_typing_style[[2]] < median_wpm_by_typing_style[[2]],"skewed-left", ifelse(mean_wpm_by_typing_style[[2]] > median_wpm_by_typing_style[[2]], "skewed-right", "identical"))`.

Both shapes are only slightly skewed as can also be seen in the visualization where the `mean` and `median` are very close.
Moreover, the distribution of `r colnames(mean_wpm_by_typing_style[2])` is more bimodal and `r  ifelse(mean_wpm_by_typing_style[[2]] < median_wpm_by_typing_style[[2]],"skewed-left", ifelse(mean_wpm_by_typing_style[[2]] > median_wpm_by_typing_style[[2]], "skewed-right", "identical"))` whereas the shape of `r colnames(mean_wpm_by_typing_style[1])` is just `r  ifelse(mean_wpm_by_typing_style[[1]] < median_wpm_by_typing_style[[1]],"skewed left", ifelse(mean_wpm_by_typing_style[[1]] > median_wpm_by_typing_style[[1]], "skewed right", "identical"))` or unimodal, as can be seen in the visualization as well.

Eventually, the numbers confirmed the initial impressions from the visualizations that there is not a big difference between the two *typing styles* with regards to the *wpms*. But there is a slight difference for example in the distribution and shape of the data.

#### Histograms

```{r echo=FALSE, results='hide'}
# setup for histogram plots
rounded_min <- floor(min(data$wpm))
rounded_max <- ceiling(max(data$wpm))
nr_of_bins <- 10
```

```{r, echo=FALSE}
#plot histograms with distribution of wpm by styling tpyes

data %>%
  filter(typing_style ==  colnames(min_wpm_by_typing_style[1])) %>%
  select(wpm) %>% 
  unlist() %>%
  as.numeric() %>%
 hist(main=sprintf("Distribution of wpms for the %s typing_style", colnames(min_wpm_by_typing_style[1])), xlab="Words per minute (wpms)", xlim=c(rounded_min, rounded_max), breaks=nr_of_bins, col="grey")

data %>%
  filter(typing_style ==  colnames(min_wpm_by_typing_style[2])) %>%
  select(wpm) %>% 
  unlist() %>%
  as.numeric() %>%
 hist(main=sprintf("Distribution of wpms for the %s typing_style", colnames(min_wpm_by_typing_style[2])), xlab="Words per minute (wpms)", xlim=c(rounded_min, rounded_max), breaks=nr_of_bins, col="grey")
```

```{r}
# r function for skewness
by(data = data$wpm, INDICES = data$typing_style, FUN = skewness)
```









#### **RQ2 - words per minute (wpm) by condition (stimulus type)**

With RQ2 in mind we create the same plot again for *words per minute (wpm)* by the different *conditions*.

```{r, echo=FALSE, warning=FALSE}
# violin plot including boxplots displaying words per minute (wpm) for the three conditions
data %>% 
 ggplot(aes(x=condition, y=wpm, fill=condition)) + 
  geom_violin() + 
  geom_boxplot(width=0.1) +
  # add mean to compare to median
  stat_summary(fun=mean, geom="point",  aes(shape="mean"), , size=5, color="red", fill="red") +
  scale_shape_manual("", values=c("mean"="x")) +
  scale_fill_brewer(palette="Blues") + 
  theme_minimal() +
  labs(title="Words Per Minute (WPM) by Condition",x="Condition", y = "Words Per Minute (WPM)") +
  guides(fill=guide_legend(title="Condition"))
```

In contrast to the visualization before, in this case we immediately see that the violin and boxplots appear quite different with regards to the *conditions* and *word per minutes (wpm)*. Hence we should again have a closer look at the numbers again.


**Non-Parametric Statistics**

```{r, echo=FALSE}
# median of wpm per typing style
median_wpm_by_condition <- by(data = data$wpm, INDICES = data$condition, FUN = median) %>%
  rbind() %>%
  as_tibble()

# min of wpm per typing style
min_wpm_by_condition <- by(data = data$wpm, INDICES = data$condition, FUN = min) %>%
  rbind() %>%
  as_tibble()

# max of wpm per typing style
max_wpm_by_condition <- by(data = data$wpm, INDICES = data$condition, FUN = max) %>%
  rbind() %>%
  as_tibble()

# IQR of wpm per typing style
iqr_wpm_by_condition <- by(data = data$wpm, INDICES = data$condition, FUN = IQR) %>%
  rbind() %>%
  as_tibble()

```


* Median:
  + `r colnames(median_wpm_by_condition[1])` has a `median` of `r median_wpm_by_condition[[1]]` *wpms*, `r colnames(median_wpm_by_condition[2])` has a `median` of `r median_wpm_by_condition[[2]]` *wpms* and `r colnames(median_wpm_by_condition[3])` has a `median` of `r median_wpm_by_condition[[3]]` *wpms*.

* Min and Max Values:
  + For the `min` values `r colnames(min_wpm_by_condition[1])` has a value of `r min_wpm_by_condition[[1]]` *wpms*, `r colnames(min_wpm_by_condition[2])` has a value of `r min_wpm_by_condition[[2]]` *wpms* and  `r colnames(min_wpm_by_condition[3])` has a value of `r min_wpm_by_condition[[3]]` *wpms*.
  + Regarding the `max`values `r colnames(max_wpm_by_condition[1])` has a value of `r max_wpm_by_condition[[1]]` *wpms*, `r colnames(max_wpm_by_condition[2])` has a value of `r max_wpm_by_condition[[2]]` *wpms* and  `r colnames(max_wpm_by_condition[3])` has a value of `r max_wpm_by_condition[[3]]` *wpms*.
  
* Interquartile Range (IQR) :
  + The `IQR` of `r colnames(iqr_wpm_by_condition[1])` amounts to `r iqr_wpm_by_condition[[1]]`, the `IQR` for  `r colnames(iqr_wpm_by_condition[2])` to `r iqr_wpm_by_condition[[2]]` and on the `IQR` for  `r colnames(iqr_wpm_by_condition[3])` to `r iqr_wpm_by_condition[[3]]`.



The `median`, `min`, `max`, as well as the `IQR` this time show significant differences that are also obvious in the visualizations. Upon these we can already make a statement about RQ2.


* Condition `r colnames(max_wpm_by_condition[1])`:
  + User who had to type strings in form of `r colnames(iqr_wpm_by_condition[1])` were the slowest compared to the other conditions. This shows in the lowest `median` (`r `median_wpm_by_condition[[1]]`), `min`(`r min_wpm_by_condition[[1]]`) and `max` (`r max_wpm_by_condition[[1]]`) values. 
  + But these users had a very small spread which is by the  `IQR of` (`r iqr_wpm_by_condition[[1]]`) that is lower than the others.

* Condition `r colnames(max_wpm_by_condition[2])`:
  + User who had to type strings in `r colnames(iqr_wpm_by_condition[2])` form were faster than `r colnames(iqr_wpm_by_condition[1])` strings but slower than regular `r colnames(iqr_wpm_by_condition[3])`.
  + They had larger spread indicated by the `IQR of`(`r iqr_wpm_by_condition[[3]]`) but not the largest compared to the others .

* Condition `r colnames(max_wpm_by_condition[3])`:
  + User who had to type strings in form of `r colnames(iqr_wpm_by_condition[3])` were the fastest, which is shown in the highest `median`  (`r median_wpm_by_condition[[3]]`), `min`(`r min_wpm_by_condition[[3]]`) and `max` (`r max_wpm_by_condition[[3]]`) values compared to the other conditions. 
  + Also they had the largest spread indicated by the `IQR of`(`r iqr_wpm_by_condition[[3]]`) that is higher than the others. 
  
At this point we can already say that there are obvious differences between the *conditions*.


**Parametric Statistics**

```{r, echo=FALSE}
# mean of wpm per typing style
mean_wpm_by_condition <- by(data = data$wpm, INDICES = data$condition, FUN = mean) %>%
  rbind() %>%
  as_tibble()

# variation of wpm per typing style
var_wpm_by_condition <- by(data = data$wpm, INDICES = data$condition, FUN = var) %>%
  rbind() %>%
  as_tibble()

# standard deviation of wpm per typing style
sd_wpm_by_condition <- by(data = data$wpm, INDICES = data$condition, FUN = sd) %>%
  rbind() %>%
  as_tibble()

```


* Mean:
  + For the `r colnames(mean_wpm_by_condition[1])` users have  a `mean` of `r mean_wpm_by_condition[[1]]` *wpms*,  for`r colnames(mean_wpm_by_condition[2])` a `mean` of `r   mean_wpm_by_condition[[2]]`    *wpms* and  for`r colnames(mean_wpm_by_condition[3])` has a `mean` of `r mean_wpm_by_condition[[3]]` *wpms*.

* Spread:
  + For the variance (`var`), `r colnames(min_wpm_by_condition[1])` has a value of `r var_wpm_by_condition[[1]]`, `r colnames(var_wpm_by_condition[2])` has a value of `r var_wpm_by_condition[[2]]` and  `r colnames(var_wpm_by_condition[3])` has a value of `r var_wpm_by_condition[[3]]`.
  + Regarding the standard deviation, (`sd`) `r colnames(sd_wpm_by_condition[1])` accounts to `r sd_wpm_by_condition[[1]]`, `r colnames(sd_wpm_by_condition[2])` to `r sd_wpm_by_condition[[2]]` and `r colnames(sd_wpm_by_condition[3])` to `r sd_wpm_by_condition[[3]]`.
  


After getting the concrete values for `mean`, variance(`var`) and standard deviation(`sd`) of the data, we can again make a few statements about the distribution and the shape.
From the visualization we already see that the mean (*marked as red dots*) and the median for all of the three *conditions* are very very close to each other.


Looking at the concrete numbers for both the `mean` and the `median` for *condtitions* by *wpms* this gets clearer:

* Condition `r colnames(max_wpm_by_condition[1])`:
  + For `r colnames(mean_wpm_by_condition[1])` that have a `mean` of `r mean_wpm_by_condition[[1]]` *wpms* and a `median` of `r median_wpm_by_condition[[1]]` *wpms*.

* Condition `r colnames(max_wpm_by_condition[2])`:
  + The same applies for `r colnames(mean_wpm_by_condition[2])` with a `mean` of `r mean_wpm_by_condition[[2]]` *wpms* and a `median` of `r median_wpm_by_condition[[2]]` *wpms*.

* Condition `r colnames(max_wpm_by_condition[3])`:
  + For `r colnames(mean_wpm_by_condition[3])` the `mean` is `r mean_wpm_by_condition[[3]]` *wpms* and the `median` is  `r median_wpm_by_condition[[3]]` *wpms*.

Out of this numbers we see that the differences for `r colnames(max_wpm_by_condition[1])` and `r colnames(max_wpm_by_condition[2])` are very marginal and do not really imply a skewness as can be seen on the visualizations. Thus, we can say that both distributions are very very close to a normal distribution.
For the `r colnames(max_wpm_by_condition[2])` *condition* the spread is also very small, which says that most people are constantly slow when typing in `r colnames(max_wpm_by_condition[2])` strings. For the `r colnames(max_wpm_by_condition[1])` *condition* the spread is already bigger, where some people show to get along better with typing in `r colnames(max_wpm_by_condition[1])` strings.

Then for the `r colnames(max_wpm_by_condition[3])` *condition* the difference `mean` and `median` is still very close but a bit larger, since it can also be visually be distinguished in the visualization. Hence, it can be argued that the shape of `r colnames(mean_wpm_by_condition[3])` is minimally `r colnames(mean_wpm_by_condition[3])` is just `r  ifelse(mean_wpm_by_condition[[3]] < median_wpm_by_condition[[3]],"skewed left", ifelse(mean_wpm_by_condition[[3]] > median_wpm_by_condition[[3]], "skewed right", "identical"))`. The visualization shows that the spread here is bigger and there are the largest differences regarding *wpms* for users who had to type in whole regular `r colnames(max_wpm_by_condition[3])`. 


Both shapes are only slightly skewed as can also be seen in the visualization where the `mean` and `median` are very close.
Moreover, the distribution of `r colnames(mean_wpm_by_condition[2])` is more bimodal and `r  ifelse(mean_wpm_by_condition[[2]] < median_wpm_by_condition[[2]],"skewed-left", ifelse(mean_wpm_by_condition[[2]] > median_wpm_by_condition[[2]], "skewed-right", "identical"))` whereas the shape of `r colnames(mean_wpm_by_condition[1])` is just `r  ifelse(mean_wpm_by_condition[[1]] < median_wpm_by_condition[[1]],"skewed left", ifelse(mean_wpm_by_condition[[1]] > median_wpm_by_condition[[1]], "skewed right", "identical"))` or unimodal, as can be seen in the visualization as well.

Eventually, for this case the the numbers related to the spread of the data (variance(`var`), standard deviation(`sd`), `IQR`) do confirm the impression of the visualization that there are significant differences. The `mean` and `median` do not show big differences at all for all three conditions.



#### Histograms

```{r, echo=FALSE}
#plot histograms with distribution of wpm by conditions

data %>%
  filter(condition ==  colnames(min_wpm_by_condition[1])) %>%
  select(wpm) %>% 
  unlist() %>%
  as.numeric() %>%
 hist(main=sprintf("Distribution of wpms for the %s string condition", colnames(min_wpm_by_condition[1])), xlab="Words per minute (wpms)", xlim=c(rounded_min, rounded_max), breaks=nr_of_bins, col="grey")

data %>%
  filter(condition ==  colnames(min_wpm_by_condition[2])) %>%
  select(wpm) %>% 
  unlist() %>%
  as.numeric() %>%
 hist(main=sprintf("Distribution of wpms for the %s string condition", colnames(min_wpm_by_condition[2])), xlab="Words per minute (wpms)", xlim=c(rounded_min, rounded_max), breaks=nr_of_bins, col="grey")

data %>%
  filter(condition ==  colnames(min_wpm_by_condition[3])) %>%
  select(wpm) %>% 
  unlist() %>%
  as.numeric() %>%
 hist(main=sprintf("Distribution of wpms for the %s string condition", colnames(min_wpm_by_condition[3])), xlab="Words per minute (wpms)", xlim=c(rounded_min, rounded_max), breaks=nr_of_bins, col="grey")

```


***


### Statistical Assumptions ###

TODO: include inferential statistics here already?


***


## Data Variation & Validity ##

### Linear Model ###

test columns using inferential statistics

#### Construct Linear Model ####

#### Model-fit Assessment ####

#### Estimations ####

#### Test Statistical Assumptions for the model ####


## Results ##









